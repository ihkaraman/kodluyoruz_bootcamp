{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings            \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    # verinin okunması\n",
    "    data = pd.read_csv('M30_EURUSD.csv',low_memory=False)\n",
    "    # soru işaretleri olan satırlar veriden silindi.\n",
    "    data = data.replace(\"?\", np.nan)\n",
    "    # data = data.dropna()\n",
    "    # verinin feature larının ayrılması\n",
    "    df = data.iloc[:,5:430]\n",
    "    df_first = data.iloc[:,1:5]\n",
    "    df_result = data.iloc[:,430:-1]\n",
    "    return df, df_first, df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametrik fonk. tanımlaması\n",
    "# 1 : \n",
    "# 2 :\n",
    "\n",
    "def kategorikleri_dummy_yap(df):\n",
    "    cat_column_names = ['ind_7','ind_11','ind_24','ind_38','ind_54','ind_57','ind_60','ind_63','ind_66','ind_69','ind_72','ind_75',\n",
    "                    'ind_78','ind_81','ind_84','ind_87','ind_89','ind_91','ind_93','ind_95','ind_97','ind_99','ind_101',\n",
    "                    'ind_103','ind_105','ind_107','ind_109', 'ind_111', 'ind_113', 'ind_115','ind_138','ind_141','ind_144',\n",
    "                    'ind_157','ind_159','ind_161','ind_163','ind_165','ind_167','ind_169','ind_171','ind_173','ind_175',\n",
    "                    'ind_177','ind_182','ind_184','ind_187','ind_190','ind_193','ind_196','ind_199','ind_202','ind_205',\n",
    "                    'ind_208','ind_211','ind_213','ind_384','ind_386','ind_388','ind_390']\n",
    "    # categorical kolonların dummy var. oalrak değiştirdik\n",
    "    dms = pd.get_dummies(df[cat_column_names])\n",
    "    dms_none_cols = dms.filter(regex = '_NONE').columns\n",
    "    for i in dms_none_cols:\n",
    "        dms.drop(i,axis=1,inplace=True)\n",
    "    dms_red_cols = dms.filter(regex = '_RED').columns\n",
    "    for i in dms_red_cols:\n",
    "        dms.drop(i,axis=1,inplace=True)\n",
    "    #datadan categorical olan kolonları çıkarıyoruz ve type nı değiştiriyoruz\n",
    "    df_noncategoric = df.drop(cat_column_names,axis=1).astype(\"float64\")\n",
    "    from sklearn.preprocessing import Imputer \n",
    "    imputer= Imputer(missing_values='NaN', strategy = 'mean', axis=0 ) \n",
    "    imputer = imputer.fit(df_noncategoric)   \n",
    "    df_noncategoric = imputer.transform(df_noncategoric) \n",
    "    df_noncategoric = pd.DataFrame(df_noncategoric)\n",
    "    df_all = pd.concat([df_noncategoric, dms], axis=1)\n",
    "    # y değerlerinin alınması\n",
    "    return df_all, df_noncategoric, dms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 - dropping correlaritions\n",
    "def corr_df(df, corr_val):\n",
    "    corr_matrix = df_noncategoric.corr().abs()\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    # Find index of feature columns with correlation greater than 0.95\n",
    "    to_high = [column for column in upper.columns if any(upper[column] > corr_val)]\n",
    "    df.drop(to_high, axis = 1, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 RandomForest\n",
    "# bütün değişkenlerle yapılan random forest sonucu importance değeri verilen parametreden büyük olan değişkenleri döner\n",
    "def rand_forest(X, y, imp_value):\n",
    "    rf_model = RandomForestClassifier().fit(X, y)\n",
    "    Importance = pd.DataFrame({'Importance':rf_model.feature_importances_*100}, index = X.columns)\n",
    "    imp_values = Importance.sort_values(by = 'Importance', axis = 0, ascending = True)\n",
    "    imp_values = imp_values[imp_values['Importance']>imp_value]\n",
    "    col_names = imp_values.index   \n",
    "    return X[col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 - pca\n",
    "def pca_fon(X, threshold):\n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(scale(X))\n",
    "    arr = np.cumsum(np.round(pca.explained_variance_ratio_, decimals = 4)*100)\n",
    "    num_var = sum((arr < threshold*100)) + 1 \n",
    "    print('pca sonrası değişken sayısı: ',num_var)\n",
    "    X_pcad = pd.DataFrame(X_pca[:,0:num_var], index = X.index)\n",
    "    return X_pcad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(X, y, test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, shuffle = False)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.1 - multi lojistik\n",
    "def multi_logit(X_train, X_test, y_train, y_test):\n",
    "    logreg = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial')\n",
    "    log = logreg.fit(X_train, y_train)\n",
    "    y_pred = log.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.2 - decision tree\n",
    "def dec_tree(X_train, X_test, y_train, y_test):\n",
    "    cart = DecisionTreeClassifier()\n",
    "    cart_model = cart.fit(X_train, y_train)\n",
    "    y_pred = cart_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_boost(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    print('grad_boost----------------')\n",
    "    gbm_model = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "    y_pred = gbm_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_boost(X_train, X_test, y_train, y_test):\n",
    "    from xgboost import XGBClassifier\n",
    "    print('xgb_boost----------------')\n",
    "    xgb_model = XGBClassifier().fit(X_train, y_train)\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightGBM(X_train, X_test, y_train, y_test):\n",
    "    from lightgbm import LGBMClassifier\n",
    "    print('lightGBM----------------')\n",
    "    lgbm_model = LGBMClassifier(verbose=-1).fit(X_train,y_train)    \n",
    "    y_pred = lgbm_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catBoost(X_train, X_test, y_train, y_test):\n",
    "    from catboost import CatBoostClassifier\n",
    "    print('CatBoost----------------')\n",
    "    cat_model = CatBoostClassifier().fit(X_train, y_train)\n",
    "    y_pred = cat_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.3 - Boosting\n",
    "def boostings(X_train, X_test, y_train, y_test):\n",
    "    grad_boost(X_train, X_test, y_train, y_test)\n",
    "    xgb_boost(X_train, X_test, y_train, y_test)\n",
    "    # lightGBM(X_train, X_test, y_train, y_test)\n",
    "    # catBoost(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verinin okunması - df: ilk 5 kolon ve result'lar hariç kolonlar, df_first: ilk 5 kolon, df_result: sonuç kolonları\n",
    "df, df_first, df_result = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  BUY\n",
       "1  BUY\n",
       "2  BUY\n",
       "3  BUY\n",
       "4  BUY"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y sütunlarında geçen verilerden en çok tekrar edenler y sütunu olarak alınmıştır.\n",
    "# desc = y.T.describe(include='all')\n",
    "y_max1 = df_result.mode(axis=1)\n",
    "y = pd.DataFrame(y_max1[0])\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 den gelen veriler (non correlatedlardan gelenler)\n",
    "df_all, df_noncategoric, dms = kategorikleri_dummy_yap(df)\n",
    "df_noncorr = corr_df(df_noncategoric, 0.50)\n",
    "X1_1 = pd.concat([df_first, df_noncorr, dms], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 den gelen veriler. \n",
    "# Notlar: \n",
    "# 1 - y için iterasyon denenebilir. y kolonu '220_signal' seçilmiştir.\n",
    "# 2- importance treshold'u 0.05 seçilmiştir, cv yapılabilir.\n",
    "\n",
    "X_raw = pd.concat([df_first,df_all], axis=1) \n",
    "X1_2 = rand_forest(X_raw, y, 0.05)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca sonrası değişken sayısı:  201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((27994, 485), (27994, 201))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.3 den gelen veriler.\n",
    "X_raw2 = pd.concat([df_first,df_all], axis=1) \n",
    "X1_3 = pca_fon(X_raw2, 0.99)\n",
    "X_raw2.shape, X1_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_1 için multi log\n",
      "Accuracy:  0.35535714285714287\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[382   0 473]\n",
      " [338   0 161]\n",
      " [833   0 613]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.25      0.45      0.32       855\n",
      "        NONE       0.00      0.00      0.00       499\n",
      "        SELL       0.49      0.42      0.46      1446\n",
      "\n",
      "    accuracy                           0.36      2800\n",
      "   macro avg       0.25      0.29      0.26      2800\n",
      "weighted avg       0.33      0.36      0.33      2800\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, y_train, y_test = splitting(X1_1, y, 0.10)\n",
    "print('X1_1 için multi log')\n",
    "multi_logit(X_train1, X_test1, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_2 için multi log\n",
      "Accuracy:  0.37107142857142855\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[523   3 329]\n",
      " [391   0 108]\n",
      " [930   0 516]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.28      0.61      0.39       855\n",
      "        NONE       0.00      0.00      0.00       499\n",
      "        SELL       0.54      0.36      0.43      1446\n",
      "\n",
      "    accuracy                           0.37      2800\n",
      "   macro avg       0.28      0.32      0.27      2800\n",
      "weighted avg       0.37      0.37      0.34      2800\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_test2, y_train, y_test = splitting(X1_2, y, 0.10)\n",
    "print('X1_2 için multi log')\n",
    "multi_logit(X_train2, X_test2, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_3 için multi log\n",
      "Accuracy:  0.3225\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[ 648   45  162]\n",
      " [ 453   19   27]\n",
      " [1118   92  236]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.29      0.76      0.42       855\n",
      "        NONE       0.12      0.04      0.06       499\n",
      "        SELL       0.56      0.16      0.25      1446\n",
      "\n",
      "    accuracy                           0.32      2800\n",
      "   macro avg       0.32      0.32      0.24      2800\n",
      "weighted avg       0.40      0.32      0.27      2800\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train3, X_test3, y_train, y_test = splitting(X1_3, y, 0.10)\n",
    "print('X1_3 için multi log')\n",
    "multi_logit(X_train3, X_test3, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_1 için dec tree\n",
      "Accuracy:  0.37392857142857144\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[288 288 279]\n",
      " [223 173 103]\n",
      " [383 477 586]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.32      0.34      0.33       855\n",
      "        NONE       0.18      0.35      0.24       499\n",
      "        SELL       0.61      0.41      0.49      1446\n",
      "\n",
      "    accuracy                           0.37      2800\n",
      "   macro avg       0.37      0.36      0.35      2800\n",
      "weighted avg       0.44      0.37      0.39      2800\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, y_train, y_test = splitting(X1_1, y, 0.10)\n",
    "print('X1_1 için dec tree')\n",
    "dec_tree(X_train1, X_test1, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_2 için dec tree\n",
      "Accuracy:  0.3142857142857143\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[369 305 181]\n",
      " [174 121 204]\n",
      " [632 424 390]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.31      0.43      0.36       855\n",
      "        NONE       0.14      0.24      0.18       499\n",
      "        SELL       0.50      0.27      0.35      1446\n",
      "\n",
      "    accuracy                           0.31      2800\n",
      "   macro avg       0.32      0.31      0.30      2800\n",
      "weighted avg       0.38      0.31      0.32      2800\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_test2, y_train, y_test = splitting(X1_2, y, 0.10)\n",
    "print('X1_2 için dec tree')\n",
    "dec_tree(X_train2, X_test2, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  kolonu için sonuçlar:\n",
      "Accuracy:  0.36678571428571427\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[416  64 375]\n",
      " [225  32 242]\n",
      " [749 118 579]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.30      0.49      0.37       855\n",
      "        NONE       0.15      0.06      0.09       499\n",
      "        SELL       0.48      0.40      0.44      1446\n",
      "\n",
      "    accuracy                           0.37      2800\n",
      "   macro avg       0.31      0.32      0.30      2800\n",
      "weighted avg       0.37      0.37      0.36      2800\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train3, X_test3, y_train, y_test = splitting(X1_3, y, 0.10)\n",
    "for i in y.columns:\n",
    "    print(i, ' kolonu için sonuçlar:')\n",
    "    dec_tree(X_train3, X_test3, y_train[i], y_test[i])\n",
    "    print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  kolonu için sonuçlar:\n",
      "grad_boost----------------\n",
      "Accuracy:  0.39659483271818075\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[2746    0  312]\n",
      " [1386    9  149]\n",
      " [3215    6  576]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.37      0.90      0.53      3058\n",
      "        NONE       0.60      0.01      0.01      1544\n",
      "        SELL       0.56      0.15      0.24      3797\n",
      "\n",
      "    accuracy                           0.40      8399\n",
      "   macro avg       0.51      0.35      0.26      8399\n",
      "weighted avg       0.50      0.40      0.30      8399\n",
      "\n",
      "xgb_boost----------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-628ac94ef308>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' kolonu için sonuçlar:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mboostings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*************************************************************************************'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-5d1d6417074a>\u001b[0m in \u001b[0;36mboostings\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mboostings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mgrad_boost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mxgb_boost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m# lightGBM(X_train, X_test, y_train, y_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# catBoost(X_train, X_test, y_train, y_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-585eaf051861>\u001b[0m in \u001b[0;36mxgb_boost\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'xgb_boost----------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mxgb_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mconfusion_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1109\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, y_train, y_test = splitting(X1_1, y, 0.30)\n",
    "for i in y.columns:\n",
    "    print(i, ' kolonu için sonuçlar:')\n",
    "    boostings(X_train1, X_test1, y_train[i], y_test[i])\n",
    "    print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train, y_test = splitting(X1_2, y, 0.30)\n",
    "for i in y.columns:\n",
    "    print(i, ' kolonu için sonuçlar:')\n",
    "    boostings(X_train2, X_test2, y_train[i], y_test[i])\n",
    "    print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3, X_test3, y_train, y_test = splitting(X1_3, y, 0.30)\n",
    "for i in y.columns:\n",
    "    print(i, ' kolonu için sonuçlar:')\n",
    "    boostings(X_train3, X_test3, y_train[i], y_test[i])\n",
    "    print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yol haritası\n",
    "\n",
    "1. verilerin sadeleştirilmesi \n",
    "\n",
    "    1.1 correlatedları atarak non correlated ları bul \n",
    " \n",
    "    1.2 RandomForest'dan important değişkenleri bul \n",
    " \n",
    "    1.3 pca  \n",
    " \n",
    " \n",
    "2. algoritmalar \n",
    "\n",
    "    2.1 algoritmaları fonk. olarak yaz\n",
    " \n",
    "        2.1.1 loj reg\n",
    "  \n",
    "        2.1.2 decision tree\n",
    "  \n",
    "        2.1.3 boosting\n",
    "      \n",
    "    2.2 cross validations\n",
    " \n",
    "    2.3 1'de bulduğun verilerle bütün algoritmaları çalıştır, sonuçları kıyasla \n",
    " \n",
    " Notlar:\n",
    " - ilk 5 sütun correlation a koyulmadı. bunların da koyulması gerekir mi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# multi_logit(X, y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

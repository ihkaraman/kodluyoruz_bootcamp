{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings            \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    # verinin okunması\n",
    "    data = pd.read_csv('M30_EURUSD.csv',low_memory=False)\n",
    "    # soru işaretleri olan satırlar veriden silindi.\n",
    "    data = data.replace(\"?\", np.nan)\n",
    "    # data = data.dropna()\n",
    "    # verinin feature larının ayrılması\n",
    "    df = data.iloc[:,5:430]\n",
    "    df_first = data.iloc[:,1:5]\n",
    "    df_result = data.iloc[:,430:-1]\n",
    "    df_result = df_result.astype('category')\n",
    "    return df, df_first, df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametrik fonk. tanımlaması\n",
    "# 1 : \n",
    "# 2 :\n",
    "\n",
    "def kategorikleri_dummy_yap(df):\n",
    "    cat_column_names = ['ind_7','ind_11','ind_24','ind_38','ind_54','ind_57','ind_60','ind_63','ind_66','ind_69','ind_72','ind_75',\n",
    "                    'ind_78','ind_81','ind_84','ind_87','ind_89','ind_91','ind_93','ind_95','ind_97','ind_99','ind_101',\n",
    "                    'ind_103','ind_105','ind_107','ind_109', 'ind_111', 'ind_113', 'ind_115','ind_138','ind_141','ind_144',\n",
    "                    'ind_157','ind_159','ind_161','ind_163','ind_165','ind_167','ind_169','ind_171','ind_173','ind_175',\n",
    "                    'ind_177','ind_182','ind_184','ind_187','ind_190','ind_193','ind_196','ind_199','ind_202','ind_205',\n",
    "                    'ind_208','ind_211','ind_213','ind_384','ind_386','ind_388','ind_390']\n",
    "    # categorical kolonların dummy var. oalrak değiştirdik\n",
    "    dms = pd.get_dummies(df[cat_column_names])\n",
    "    dms_none_cols = dms.filter(regex = '_NONE').columns\n",
    "    for i in dms_none_cols:\n",
    "        dms.drop(i,axis=1,inplace=True)\n",
    "    dms_red_cols = dms.filter(regex = '_RED').columns\n",
    "    for i in dms_red_cols:\n",
    "        dms.drop(i,axis=1,inplace=True)\n",
    "    #datadan categorical olan kolonları çıkarıyoruz ve type nı değiştiriyoruz\n",
    "    df_noncategoric = df.drop(cat_column_names,axis=1).astype(\"float64\")\n",
    "    df_noncategoric = pd.DataFrame(df_noncategoric)\n",
    "    df_all = pd.concat([df_noncategoric, dms], axis=1)\n",
    "    # y değerlerinin alınması\n",
    "    return df_all, df_noncategoric, dms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kateg_type_degistir(df):\n",
    "    cat_column_names = ['ind_7','ind_11','ind_24','ind_38','ind_54','ind_57','ind_60','ind_63','ind_66','ind_69','ind_72','ind_75',\n",
    "                'ind_78','ind_81','ind_84','ind_87','ind_89','ind_91','ind_93','ind_95','ind_97','ind_99','ind_101',\n",
    "                'ind_103','ind_105','ind_107','ind_109', 'ind_111', 'ind_113', 'ind_115','ind_138','ind_141','ind_144',\n",
    "                'ind_157','ind_159','ind_161','ind_163','ind_165','ind_167','ind_169','ind_171','ind_173','ind_175',\n",
    "                'ind_177','ind_182','ind_184','ind_187','ind_190','ind_193','ind_196','ind_199','ind_202','ind_205',\n",
    "                'ind_208','ind_211','ind_213','ind_384','ind_386','ind_388','ind_390']\n",
    "    tmp = [x for x in df.columns if x not in cat_column_names]\n",
    "    for i in cat_column_names:\n",
    "        df[i] = df[i].astype('category')\n",
    "    for i in tmp:\n",
    "        df[i] = df[i].astype('float64')   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 - dropping correlaritions\n",
    "def corr_df(df, corr_val):\n",
    "    corr_matrix = df_noncategoric.corr().abs()\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    # Find index of feature columns with correlation greater than 0.95\n",
    "    to_high = [column for column in upper.columns if any(upper[column] > corr_val)]\n",
    "    df.drop(to_high, axis = 1, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 RandomForest\n",
    "# bütün değişkenlerle yapılan random forest sonucu importance değeri verilen parametreden büyük olan değişkenleri döner\n",
    "def rand_forest(X, y, imp_value):\n",
    "    rf_model = RandomForestClassifier().fit(X, y)\n",
    "    Importance = pd.DataFrame({'Importance':rf_model.feature_importances_*100}, index = X.columns)\n",
    "    imp_values = Importance.sort_values(by = 'Importance', axis = 0, ascending = True)\n",
    "    imp_values = imp_values[imp_values['Importance']>imp_value]\n",
    "    col_names = imp_values.index   \n",
    "    return X[col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 - pca\n",
    "def pca_fon(X, threshold):\n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(scale(X))\n",
    "    arr = np.cumsum(np.round(pca.explained_variance_ratio_, decimals = 4)*100)\n",
    "    num_var = sum((arr < threshold*100)) + 1 \n",
    "    print('pca sonrası değişken sayısı: ',num_var)\n",
    "    X_pcad = pd.DataFrame(X_pca[:,0:num_var], index = X.index)\n",
    "    return X_pcad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(X, y, test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, shuffle = False)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.1 - multi lojistik\n",
    "def multi_logit(X_train, X_test, y_train, y_test):\n",
    "    logreg = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial')\n",
    "    log = logreg.fit(X_train, y_train)\n",
    "    y_pred = log.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.2 - decision tree\n",
    "def dec_tree(X_train, X_test, y_train, y_test):\n",
    "    cart = DecisionTreeClassifier()\n",
    "    cart_model = cart.fit(X_train, y_train)\n",
    "    y_pred = cart_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_boost(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    print('grad_boost----------------')\n",
    "    gbm_model = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "    y_pred = gbm_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_boost(X_train, X_test, y_train, y_test):\n",
    "    from xgboost import XGBClassifier\n",
    "    print('xgb_boost----------------')\n",
    "    xgb_model = XGBClassifier().fit(X_train, y_train)\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightGBM(X_train, X_test, y_train, y_test):\n",
    "    from lightgbm import LGBMClassifier\n",
    "    print('lightGBM----------------')\n",
    "    lgbm_model = LGBMClassifier(verbose=-1).fit(X_train,y_train)    \n",
    "    y_pred = lgbm_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catBoost(X_train, X_test, y_train, y_test):\n",
    "    from catboost import CatBoostClassifier\n",
    "    print('CatBoost----------------')\n",
    "    cat_model = CatBoostClassifier().fit(X_train, y_train)\n",
    "    y_pred = cat_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.3 - Boosting\n",
    "def boostings(X_train, X_test, y_train, y_test):\n",
    "    grad_boost(X_train, X_test, y_train, y_test)\n",
    "    xgb_boost(X_train, X_test, y_train, y_test)\n",
    "    # lightGBM(X_train, X_test, y_train, y_test)\n",
    "    # catBoost(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.2 - decision tree\n",
    "def dec_tree_withcv(X_train, X_test, y_train, y_test):\n",
    "    cart = DecisionTreeClassifier()\n",
    "    cart_model = cart.fit(X_train, y_train)\n",
    "    y_pred = cart_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verinin okunması - df: ilk 5 kolon ve result'lar hariç kolonlar, df_first: ilk 5 kolon, df_result: sonuç kolonları\n",
    "df, df_first, df_result = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# katogorik değişkenlerin tipinin kategorik yapılması\n",
    "df1 = kateg_type_degistir(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  BUY\n",
       "1  BUY\n",
       "2  BUY\n",
       "3  BUY\n",
       "4  BUY"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_max1 = df_result.mode(axis=1)\n",
    "y = pd.DataFrame(y_max1[0])\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27994 entries, 0 to 27993\n",
      "Data columns (total 1 columns):\n",
      "0    27994 non-null category\n",
      "dtypes: category(1)\n",
      "memory usage: 27.6 KB\n"
     ]
    }
   ],
   "source": [
    "y = y.astype('category')\n",
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27994 entries, 0 to 27993\n",
      "Columns: 429 entries, open to ind_429\n",
      "dtypes: category(60), float64(369)\n",
      "memory usage: 80.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.concat([df_first, df1], axis=1)\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X4_1 = rand_forest(df_raw, y, 0.05) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'BUY'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-4b54a1e2ea5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX4_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca_fon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_raw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_raw2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX1_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-7ad330000ed0>\u001b[0m in \u001b[0;36mpca_fon\u001b[1;34m(X, threshold)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpca_fon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mX_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mnum_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mscale\u001b[1;34m(X, axis, with_mean, with_std, copy)\u001b[0m\n\u001b[0;32m    139\u001b[0m     X = check_array(X, accept_sparse='csc', copy=copy, ensure_2d=False,\n\u001b[0;32m    140\u001b[0m                     \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'the scale function'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                     force_all_finite='allow-nan')\n\u001b[0m\u001b[0;32m    142\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'BUY'"
     ]
    }
   ],
   "source": [
    "X4_2 = pca_fon(df_raw, 0.99)\n",
    "X_raw2.shape, X1_3.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4_1, X_test4_1, y_train, y_test = splitting(df_raw, y, 0.10)\n",
    "# X_train4_2, X_test4_2, y_train, y_test = splitting(X4_2, y, 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_1 için dec tree\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'BUY'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-987df56bca21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'4_1 için dec tree'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdec_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train4_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test4_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*************************************************************************************'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-24c9f4645e28>\u001b[0m in \u001b[0;36mdec_tree\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdec_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mcart_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mconfusion_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    817\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'BUY'"
     ]
    }
   ],
   "source": [
    "print('4_1 için dec tree')\n",
    "dec_tree(X_train4_1, X_test4_1, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('4_2 için dec tree')\n",
    "dec_tree(X_train4_2, X_test4_2, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ashdbkajsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y sütunlarında geçen verilerden en çok tekrar edenler y sütunu olarak alınmıştır.\n",
    "# desc = y.T.describe(include='all')\n",
    "y_max1 = df_result.mode(axis=1)\n",
    "y = pd.DataFrame(y_max1[0])\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 den gelen veriler (non correlatedlardan gelenler)\n",
    "df_all, df_noncategoric, dms = kategorikleri_dummy_yap(df)\n",
    "df_noncorr = corr_df(df_noncategoric, 0.50)\n",
    "X1_1 = pd.concat([df_first, df_noncorr, dms], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 den gelen veriler. \n",
    "# Notlar: \n",
    "# 1 - y için iterasyon denenebilir. y kolonu '220_signal' seçilmiştir.\n",
    "# 2- importance treshold'u 0.05 seçilmiştir, cv yapılabilir.\n",
    "\n",
    "X_raw = pd.concat([df_first,df_all], axis=1) \n",
    "X1_2 = rand_forest(X_raw, y, 0.05)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1.3 den gelen veriler.\n",
    "X_raw2 = pd.concat([df_first,df_all], axis=1) \n",
    "X1_3 = pca_fon(X_raw2, 0.99)\n",
    "X_raw2.shape, X1_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train, y_test = splitting(X1_1, y, 0.10)\n",
    "print('X1_1 için multi log')\n",
    "multi_logit(X_train1, X_test1, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train, y_test = splitting(X1_2, y, 0.10)\n",
    "print('X1_2 için multi log')\n",
    "multi_logit(X_train2, X_test2, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3, X_test3, y_train, y_test = splitting(X1_3, y, 0.10)\n",
    "print('X1_3 için multi log')\n",
    "multi_logit(X_train3, X_test3, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train, y_test = splitting(X1_1, y, 0.10)\n",
    "print('X1_1 için dec tree')\n",
    "dec_tree(X_train1, X_test1, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train, y_test = splitting(X1_2, y, 0.10)\n",
    "print('X1_2 için dec tree')\n",
    "dec_tree(X_train2, X_test2, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3, X_test3, y_train, y_test = splitting(X1_3, y, 0.10)\n",
    "for i in y.columns:\n",
    "    print(i, ' kolonu için sonuçlar:')\n",
    "    dec_tree(X_train3, X_test3, y_train[i], y_test[i])\n",
    "    print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train, y_test = splitting(X1_1, y, 0.30)\n",
    "for i in y.columns:\n",
    "    print(i, ' kolonu için sonuçlar:')\n",
    "    boostings(X_train1, X_test1, y_train[i], y_test[i])\n",
    "    print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train, y_test = splitting(X1_2, y, 0.30)\n",
    "for i in y.columns:\n",
    "    print(i, ' kolonu için sonuçlar:')\n",
    "    boostings(X_train2, X_test2, y_train[i], y_test[i])\n",
    "    print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3, X_test3, y_train, y_test = splitting(X1_3, y, 0.30)\n",
    "for i in y.columns:\n",
    "    print(i, ' kolonu için sonuçlar:')\n",
    "    boostings(X_train3, X_test3, y_train[i], y_test[i])\n",
    "    print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yol haritası\n",
    "\n",
    "1. verilerin sadeleştirilmesi \n",
    "\n",
    "    1.1 correlatedları atarak non correlated ları bul \n",
    " \n",
    "    1.2 RandomForest'dan important değişkenleri bul \n",
    " \n",
    "    1.3 pca  \n",
    " \n",
    " \n",
    "2. algoritmalar \n",
    "\n",
    "    2.1 algoritmaları fonk. olarak yaz\n",
    " \n",
    "        2.1.1 loj reg\n",
    "  \n",
    "        2.1.2 decision tree\n",
    "  \n",
    "        2.1.3 boosting\n",
    "      \n",
    "    2.2 cross validations\n",
    " \n",
    "    2.3 1'de bulduğun verilerle bütün algoritmaları çalıştır, sonuçları kıyasla \n",
    " \n",
    " Notlar:\n",
    " - ilk 5 sütun correlation a koyulmadı. bunların da koyulması gerekir mi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train, y_test = splitting(X1_1, y, 0.10)\n",
    "print('X1_1 için dec tree')\n",
    "dec_tree(X_train1, X_test1, y_train, y_test)\n",
    "print\n",
    "cart = DecisionTreeClassifier()\n",
    "cart_model = cart.fit(X_train1, y_train)\n",
    "y_pred = cart_model.predict(X_test1)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_grid = {\"max_depth\":[2,5,8,10,15,20,25,30,40,50,70,90,120,150], \"min_samples_split\":[2,5,8,10,15,20,25,30,40,50,70,90,120,150]}\n",
    "cart_cv = GridSearchCV(cart, cart_grid, cv=10, n_jobs =-1, verbose = 2)\n",
    "cart_cv_model = cart_cv.fit(X_train1, y_train)\n",
    "print('En iyi parametreler : ' + str(cart_cv_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = DecisionTreeClassifier(max_depth = 2, min_samples_split=2 )\n",
    "cart_tuned = cart.fit(X_train1, y_train)\n",
    "y_pred = cart_tuned.predict(X_test1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('accuracy : ', accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_grid = {\"max_depth\":range(1,10), \"min_samples_split\":list(range(1,20))}\n",
    "cart_cv = GridSearchCV(cart, cart_grid, cv=10, n_jobs =-1, verbose = 2)\n",
    "cart_cv_model = cart_cv.fit(X_train1, y_train)\n",
    "print('En iyi parametreler : ' + str(cart_cv_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = DecisionTreeClassifier(max_depth = 2, min_samples_split=2)\n",
    "cart_tuned = cart.fit(X_train1, y_train)\n",
    "y_pred = cart_tuned.predict(X_test1)\n",
    "accuracy_score = accuracy_score(y_test, y_pred)\n",
    "print('accuracy : ', accuracy_score)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

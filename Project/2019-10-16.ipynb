{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings            \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    # verinin okunması\n",
    "    data = pd.read_csv('M30_EURUSD.csv',low_memory=False)\n",
    "    # soru işaretleri olan satırlar veriden silindi.\n",
    "    data = data.replace(\"?\", np.nan)\n",
    "    # data = data.dropna()\n",
    "    # verinin feature larının ayrılması\n",
    "    df = data.iloc[:,5:430]\n",
    "    df_first = data.iloc[:,1:5]\n",
    "    df_result = data.iloc[:,430:-1]\n",
    "    return df, df_first, df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametrik fonk. tanımlaması\n",
    "# 1 : \n",
    "# 2 :\n",
    "\n",
    "def kategorikleri_dummy_yap(df):\n",
    "    cat_column_names = ['ind_7','ind_11','ind_24','ind_38','ind_54','ind_57','ind_60','ind_63','ind_66','ind_69','ind_72','ind_75',\n",
    "                    'ind_78','ind_81','ind_84','ind_87','ind_89','ind_91','ind_93','ind_95','ind_97','ind_99','ind_101',\n",
    "                    'ind_103','ind_105','ind_107','ind_109', 'ind_111', 'ind_113', 'ind_115','ind_138','ind_141','ind_144',\n",
    "                    'ind_157','ind_159','ind_161','ind_163','ind_165','ind_167','ind_169','ind_171','ind_173','ind_175',\n",
    "                    'ind_177','ind_182','ind_184','ind_187','ind_190','ind_193','ind_196','ind_199','ind_202','ind_205',\n",
    "                    'ind_208','ind_211','ind_213','ind_384','ind_386','ind_388','ind_390']\n",
    "    # categorical kolonların dummy var. oalrak değiştirdik\n",
    "    dms = pd.get_dummies(df[cat_column_names])\n",
    "    dms_none_cols = dms.filter(regex = '_NONE').columns\n",
    "    for i in dms_none_cols:\n",
    "        dms.drop(i,axis=1,inplace=True)\n",
    "    dms_red_cols = dms.filter(regex = '_RED').columns\n",
    "    for i in dms_red_cols:\n",
    "        dms.drop(i,axis=1,inplace=True)\n",
    "    #datadan categorical olan kolonları çıkarıyoruz ve type nı değiştiriyoruz\n",
    "    df_noncategoric = df.drop(cat_column_names,axis=1).astype(\"float64\")\n",
    "    from sklearn.preprocessing import Imputer \n",
    "    imputer= Imputer(missing_values='NaN', strategy = 'mean', axis=0 ) \n",
    "    imputer = imputer.fit(df_noncategoric)   \n",
    "    df_noncategoric = imputer.transform(df_noncategoric) \n",
    "    df_noncategoric = pd.DataFrame(df_noncategoric)\n",
    "    df_all = pd.concat([df_noncategoric, dms], axis=1)\n",
    "    # y değerlerinin alınması\n",
    "    return df_all, df_noncategoric, dms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 - dropping correlaritions\n",
    "def corr_df(df, corr_val):\n",
    "    corr_matrix = df_noncategoric.corr().abs()\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    # Find index of feature columns with correlation greater than 0.95\n",
    "    to_high = [column for column in upper.columns if any(upper[column] > corr_val)]\n",
    "    df.drop(to_high, axis = 1, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 RandomForest\n",
    "# bütün değişkenlerle yapılan random forest sonucu importance değeri verilen parametreden büyük olan değişkenleri döner\n",
    "def rand_forest(X, y, imp_value):\n",
    "    rf_model = RandomForestClassifier().fit(X, y)\n",
    "    Importance = pd.DataFrame({'Importance':rf_model.feature_importances_*100}, index = X.columns)\n",
    "    imp_values = Importance.sort_values(by = 'Importance', axis = 0, ascending = True)\n",
    "    imp_values = imp_values[imp_values['Importance']>imp_value]\n",
    "    col_names = imp_values.index   \n",
    "    return X[col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 - pca\n",
    "def pca_fon(X, threshold):\n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(scale(X))\n",
    "    arr = np.cumsum(np.round(pca.explained_variance_ratio_, decimals = 4)*100)\n",
    "    num_var = sum((arr < threshold*100)) + 1 \n",
    "    print('pca sonrası değişken sayısı: ',num_var)\n",
    "    X_pcad = pd.DataFrame(X_pca[:,0:num_var], index = X.index)\n",
    "    return X_pcad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(X, y, test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, shuffle = False)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.1 - multi lojistik\n",
    "def multi_logit(X_train, X_test, y_train, y_test):\n",
    "    logreg = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial')\n",
    "    log = logreg.fit(X_train, y_train)\n",
    "    y_pred = log.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.2 - decision tree\n",
    "def dec_tree(X_train, X_test, y_train, y_test):\n",
    "    cart = DecisionTreeClassifier()\n",
    "    cart_model = cart.fit(X_train, y_train)\n",
    "    y_pred = cart_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_boost(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    print('grad_boost----------------')\n",
    "    gbm_model = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "    y_pred = gbm_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_boost(X_train, X_test, y_train, y_test):\n",
    "    from xgboost import XGBClassifier\n",
    "    print('xgb_boost----------------')\n",
    "    xgb_model = XGBClassifier().fit(X_train, y_train)\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightGBM(X_train, X_test, y_train, y_test):\n",
    "    from lightgbm import LGBMClassifier\n",
    "    print('lightGBM----------------')\n",
    "    lgbm_model = LGBMClassifier(verbose=-1).fit(X_train,y_train)    \n",
    "    y_pred = lgbm_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catBoost(X_train, X_test, y_train, y_test):\n",
    "    from catboost import CatBoostClassifier\n",
    "    print('CatBoost----------------')\n",
    "    cat_model = CatBoostClassifier().fit(X_train, y_train)\n",
    "    y_pred = cat_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.3 - Boosting\n",
    "def boostings(X_train, X_test, y_train, y_test):\n",
    "    grad_boost(X_train, X_test, y_train, y_test)\n",
    "    xgb_boost(X_train, X_test, y_train, y_test)\n",
    "    # lightGBM(X_train, X_test, y_train, y_test)\n",
    "    # catBoost(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.2 - decision tree\n",
    "def dec_tree_withcv(X_train, X_test, y_train, y_test):\n",
    "    cart = DecisionTreeClassifier()\n",
    "    cart_model = cart.fit(X_train, y_train)\n",
    "    y_pred = cart_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verinin okunması - df: ilk 5 kolon ve result'lar hariç kolonlar, df_first: ilk 5 kolon, df_result: sonuç kolonları\n",
    "df, df_first, df_result = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  BUY\n",
       "1  BUY\n",
       "2  BUY\n",
       "3  BUY\n",
       "4  BUY"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y sütunlarında geçen verilerden en çok tekrar edenler y sütunu olarak alınmıştır.\n",
    "# desc = y.T.describe(include='all')\n",
    "y_max1 = df_result.mode(axis=1)\n",
    "y = pd.DataFrame(y_max1[0])\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 den gelen veriler (non correlatedlardan gelenler)\n",
    "df_all, df_noncategoric, dms = kategorikleri_dummy_yap(df)\n",
    "df_noncorr = corr_df(df_noncategoric, 0.50)\n",
    "X1_1 = pd.concat([df_first, df_noncorr, dms], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 den gelen veriler. \n",
    "# Notlar: \n",
    "# 1 - y için iterasyon denenebilir. y kolonu '220_signal' seçilmiştir.\n",
    "# 2- importance treshold'u 0.05 seçilmiştir, cv yapılabilir.\n",
    "\n",
    "X_raw = pd.concat([df_first,df_all], axis=1) \n",
    "X1_2 = rand_forest(X_raw, y, 0.05)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca sonrası değişken sayısı:  201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((27994, 485), (27994, 201))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.3 den gelen veriler.\n",
    "X_raw2 = pd.concat([df_first,df_all], axis=1) \n",
    "X1_3 = pca_fon(X_raw2, 0.99)\n",
    "X_raw2.shape, X1_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_1 için multi log\n",
      "Accuracy:  0.35535714285714287\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[382   0 473]\n",
      " [338   0 161]\n",
      " [833   0 613]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.25      0.45      0.32       855\n",
      "        NONE       0.00      0.00      0.00       499\n",
      "        SELL       0.49      0.42      0.46      1446\n",
      "\n",
      "    accuracy                           0.36      2800\n",
      "   macro avg       0.25      0.29      0.26      2800\n",
      "weighted avg       0.33      0.36      0.33      2800\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, y_train, y_test = splitting(X1_1, y, 0.10)\n",
    "print('X1_1 için multi log')\n",
    "multi_logit(X_train1, X_test1, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_2 için multi log\n",
      "Accuracy:  0.35678571428571426\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[516   0 339]\n",
      " [406   0  93]\n",
      " [963   0 483]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.27      0.60      0.38       855\n",
      "        NONE       0.00      0.00      0.00       499\n",
      "        SELL       0.53      0.33      0.41      1446\n",
      "\n",
      "    accuracy                           0.36      2800\n",
      "   macro avg       0.27      0.31      0.26      2800\n",
      "weighted avg       0.36      0.36      0.33      2800\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_test2, y_train, y_test = splitting(X1_2, y, 0.10)\n",
    "print('X1_2 için multi log')\n",
    "multi_logit(X_train2, X_test2, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_3 için multi log\n",
      "Accuracy:  0.3225\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[ 648   45  162]\n",
      " [ 453   19   27]\n",
      " [1118   92  236]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.29      0.76      0.42       855\n",
      "        NONE       0.12      0.04      0.06       499\n",
      "        SELL       0.56      0.16      0.25      1446\n",
      "\n",
      "    accuracy                           0.32      2800\n",
      "   macro avg       0.32      0.32      0.24      2800\n",
      "weighted avg       0.40      0.32      0.27      2800\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train3, X_test3, y_train, y_test = splitting(X1_3, y, 0.10)\n",
    "print('X1_3 için multi log')\n",
    "multi_logit(X_train3, X_test3, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_1 için dec tree\n",
      "Accuracy:  0.3582142857142857\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[413 277 165]\n",
      " [156 212 131]\n",
      " [504 564 378]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.38      0.48      0.43       855\n",
      "        NONE       0.20      0.42      0.27       499\n",
      "        SELL       0.56      0.26      0.36      1446\n",
      "\n",
      "    accuracy                           0.36      2800\n",
      "   macro avg       0.38      0.39      0.35      2800\n",
      "weighted avg       0.44      0.36      0.36      2800\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, y_train, y_test = splitting(X1_1, y, 0.10)\n",
    "print('X1_1 için dec tree')\n",
    "dec_tree(X_train1, X_test1, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_2 için dec tree\n",
      "Accuracy:  0.3382142857142857\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[411 254 190]\n",
      " [170 142 187]\n",
      " [674 378 394]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.33      0.48      0.39       855\n",
      "        NONE       0.18      0.28      0.22       499\n",
      "        SELL       0.51      0.27      0.36      1446\n",
      "\n",
      "    accuracy                           0.34      2800\n",
      "   macro avg       0.34      0.35      0.32      2800\n",
      "weighted avg       0.40      0.34      0.34      2800\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_test2, y_train, y_test = splitting(X1_2, y, 0.10)\n",
    "print('X1_2 için dec tree')\n",
    "dec_tree(X_train2, X_test2, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  kolonu için sonuçlar:\n",
      "Accuracy:  0.36678571428571427\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[417  79 359]\n",
      " [234  34 231]\n",
      " [742 128 576]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.30      0.49      0.37       855\n",
      "        NONE       0.14      0.07      0.09       499\n",
      "        SELL       0.49      0.40      0.44      1446\n",
      "\n",
      "    accuracy                           0.37      2800\n",
      "   macro avg       0.31      0.32      0.30      2800\n",
      "weighted avg       0.37      0.37      0.36      2800\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train3, X_test3, y_train, y_test = splitting(X1_3, y, 0.10)\n",
    "for i in y.columns:\n",
    "    print(i, ' kolonu için sonuçlar:')\n",
    "    dec_tree(X_train3, X_test3, y_train[i], y_test[i])\n",
    "    print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  kolonu için sonuçlar:\n",
      "grad_boost----------------\n",
      "Accuracy:  0.3952851529944041\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[2752    0  306]\n",
      " [1395    0  149]\n",
      " [3222    7  568]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.37      0.90      0.53      3058\n",
      "        NONE       0.00      0.00      0.00      1544\n",
      "        SELL       0.56      0.15      0.24      3797\n",
      "\n",
      "    accuracy                           0.40      8399\n",
      "   macro avg       0.31      0.35      0.25      8399\n",
      "weighted avg       0.39      0.40      0.30      8399\n",
      "\n",
      "xgb_boost----------------\n",
      "Accuracy:  0.3888558161685915\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[2728    0  330]\n",
      " [1371    0  173]\n",
      " [3259    0  538]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.37      0.89      0.52      3058\n",
      "        NONE       0.00      0.00      0.00      1544\n",
      "        SELL       0.52      0.14      0.22      3797\n",
      "\n",
      "    accuracy                           0.39      8399\n",
      "   macro avg       0.30      0.34      0.25      8399\n",
      "weighted avg       0.37      0.39      0.29      8399\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, y_train, y_test = splitting(X1_1, y, 0.30)\n",
    "for i in y.columns:\n",
    "    print(i, ' kolonu için sonuçlar:')\n",
    "    boostings(X_train1, X_test1, y_train[i], y_test[i])\n",
    "    print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  kolonu için sonuçlar:\n",
      "grad_boost----------------\n",
      "Accuracy:  0.39421359685676866\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[2530   58  470]\n",
      " [1392   31  121]\n",
      " [3011   36  750]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.36      0.83      0.51      3058\n",
      "        NONE       0.25      0.02      0.04      1544\n",
      "        SELL       0.56      0.20      0.29      3797\n",
      "\n",
      "    accuracy                           0.39      8399\n",
      "   macro avg       0.39      0.35      0.28      8399\n",
      "weighted avg       0.43      0.39      0.32      8399\n",
      "\n",
      "xgb_boost----------------\n",
      "Accuracy:  0.3629003452791999\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[2581    0  477]\n",
      " [1410    0  134]\n",
      " [3330    0  467]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.35      0.84      0.50      3058\n",
      "        NONE       0.00      0.00      0.00      1544\n",
      "        SELL       0.43      0.12      0.19      3797\n",
      "\n",
      "    accuracy                           0.36      8399\n",
      "   macro avg       0.26      0.32      0.23      8399\n",
      "weighted avg       0.32      0.36      0.27      8399\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_test2, y_train, y_test = splitting(X1_2, y, 0.30)\n",
    "for i in y.columns:\n",
    "    print(i, ' kolonu için sonuçlar:')\n",
    "    boostings(X_train2, X_test2, y_train[i], y_test[i])\n",
    "    print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  kolonu için sonuçlar:\n",
      "grad_boost----------------\n",
      "Accuracy:  0.3792118109298726\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[2179    3  876]\n",
      " [1236    0  308]\n",
      " [2790    1 1006]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.35      0.71      0.47      3058\n",
      "        NONE       0.00      0.00      0.00      1544\n",
      "        SELL       0.46      0.26      0.34      3797\n",
      "\n",
      "    accuracy                           0.38      8399\n",
      "   macro avg       0.27      0.33      0.27      8399\n",
      "weighted avg       0.34      0.38      0.32      8399\n",
      "\n",
      "xgb_boost----------------\n",
      "Accuracy:  0.3781402547922372\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[2169    0  889]\n",
      " [1232    0  312]\n",
      " [2790    0 1007]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.35      0.71      0.47      3058\n",
      "        NONE       0.00      0.00      0.00      1544\n",
      "        SELL       0.46      0.27      0.34      3797\n",
      "\n",
      "    accuracy                           0.38      8399\n",
      "   macro avg       0.27      0.32      0.27      8399\n",
      "weighted avg       0.33      0.38      0.32      8399\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train3, X_test3, y_train, y_test = splitting(X1_3, y, 0.30)\n",
    "for i in y.columns:\n",
    "    print(i, ' kolonu için sonuçlar:')\n",
    "    boostings(X_train3, X_test3, y_train[i], y_test[i])\n",
    "    print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yol haritası\n",
    "\n",
    "1. verilerin sadeleştirilmesi \n",
    "\n",
    "    1.1 correlatedları atarak non correlated ları bul \n",
    " \n",
    "    1.2 RandomForest'dan important değişkenleri bul \n",
    " \n",
    "    1.3 pca  \n",
    " \n",
    " \n",
    "2. algoritmalar \n",
    "\n",
    "    2.1 algoritmaları fonk. olarak yaz\n",
    " \n",
    "        2.1.1 loj reg\n",
    "  \n",
    "        2.1.2 decision tree\n",
    "  \n",
    "        2.1.3 boosting\n",
    "      \n",
    "    2.2 cross validations\n",
    " \n",
    "    2.3 1'de bulduğun verilerle bütün algoritmaları çalıştır, sonuçları kıyasla \n",
    " \n",
    " Notlar:\n",
    " - ilk 5 sütun correlation a koyulmadı. bunların da koyulması gerekir mi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_1 için dec tree\n",
      "Accuracy:  0.3360714285714286\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[376 252 227]\n",
      " [157  90 252]\n",
      " [514 457 475]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.36      0.44      0.40       855\n",
      "        NONE       0.11      0.18      0.14       499\n",
      "        SELL       0.50      0.33      0.40      1446\n",
      "\n",
      "    accuracy                           0.34      2800\n",
      "   macro avg       0.32      0.32      0.31      2800\n",
      "weighted avg       0.39      0.34      0.35      2800\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, y_train, y_test = splitting(X1_1, y, 0.10)\n",
    "print('X1_1 için dec tree')\n",
    "dec_tree(X_train1, X_test1, y_train, y_test)\n",
    "print\n",
    "cart = DecisionTreeClassifier()\n",
    "cart_model = cart.fit(X_train1, y_train)\n",
    "y_pred = cart_model.predict(X_test1)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 196 candidates, totalling 1960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1960 out of 1960 | elapsed:  7.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler : {'max_depth': 2, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "cart_grid = {\"max_depth\":[2,5,8,10,15,20,25,30,40,50,70,90,120,150], \"min_samples_split\":[2,5,8,10,15,20,25,30,40,50,70,90,120,150]}\n",
    "cart_cv = GridSearchCV(cart, cart_grid, cv=10, n_jobs =-1, verbose = 2)\n",
    "cart_cv_model = cart_cv.fit(X_train1, y_train)\n",
    "print('En iyi parametreler : ' + str(cart_cv_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.33785714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.33      0.93      0.49       855\n",
      "        NONE       0.00      0.00      0.00       499\n",
      "        SELL       0.39      0.10      0.16      1446\n",
      "\n",
      "    accuracy                           0.34      2800\n",
      "   macro avg       0.24      0.35      0.22      2800\n",
      "weighted avg       0.30      0.34      0.23      2800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cart = DecisionTreeClassifier(max_depth = 2, min_samples_split=2 )\n",
    "cart_tuned = cart.fit(X_train1, y_train)\n",
    "y_pred = cart_tuned.predict(X_test1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('accuracy : ', accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 171 candidates, totalling 1710 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\ihkar\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\ihkar\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\ihkar\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\ihkar\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\ihkar\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\ihkar\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 514, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\ihkar\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\", line 816, in fit\n    X_idx_sorted=X_idx_sorted)\n  File \"C:\\Users\\ihkar\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\", line 208, in fit\n    % self.min_samples_split)\nValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-56678cf3e807>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcart_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"max_depth\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"min_samples_split\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcart_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcart_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcart_cv_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcart_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'En iyi parametreler : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcart_cv_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    685\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    664\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 666\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1"
     ]
    }
   ],
   "source": [
    "cart_grid = {\"max_depth\":range(1,10), \"min_samples_split\":list(range(1,20))}\n",
    "cart_cv = GridSearchCV(cart, cart_grid, cv=10, n_jobs =-1, verbose = 2)\n",
    "cart_cv_model = cart_cv.fit(X_train1, y_train)\n",
    "print('En iyi parametreler : ' + str(cart_cv_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = DecisionTreeClassifier(max_depth = 2, min_samples_split=2)\n",
    "cart_tuned = cart.fit(X_train1, y_train)\n",
    "y_pred = cart_tuned.predict(X_test1)\n",
    "accuracy_score = accuracy_score(y_test, y_pred)\n",
    "print('accuracy : ', accuracy_score)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
